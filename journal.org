* emacs 中运行shell命令 :emacs

1. M-! cmd RET：打开一个名为“*Shell Command Output*“的窗口，并把该命令的执行结果显示在其中。按下”C-x 1“组合键可以关闭这个窗口。由于Shell命令的输出是在一个编辑缓冲区里，因此我们可以对它进行编辑、保存等操作。
M-| cmd RET：运行Shell命令，并使用编辑窗口中选定的区域作为该Shell命令的输入，然后可以选择是否用该Shell命令的输出来替换编辑窗口中选中的区域。
C-u M-! cmd RET：执行一条Shell命令，并将其输出放到编辑区中光标所在的位置处，而不将其输出到”Shell Command Output“窗口。
M-x shell：运行一个子Shell，该子Shell对应于emacs中的一个名为”*Shell*"的缓冲区，此后，我们就可以交互式的运行Shell命令了。
M-x term：运行一个子Shell，该子Shell对应于emacs中的一个名为“＊Terminal*”的缓冲区。使用该命令获得的子Shell是一个完整的Shell的模拟，与我们直接在Shell中操作没有什么差别。
M-x eshell：运行emacs shell。该Shell为emacs自己实现的一个shell，而前面运行的shell都为系统中的shell程序(例如：/bin/csh等）。我们可以通过设置变量shell-file-name来设置emacs所使用的默认shell)"

可以使用C-c + C-c
* 需要学习的emacs package
** ido
** yasnippet
** org
** CMAKE
** ECB
** HELM
** CEDET
** flymake

* 如何安装package，例如ecb
** 1.使用melpa包管理
** 2. 配置init-local.el
例如（require-package 'ecb)

* 不重启更新包
m-x load-file
M-x eval-buffer
* 内存数据库的设计
** 事件驱动框架，实现一个简单server
** 实现简单的数据结构，key-value结构，要考虑到性能
** 实现简单的协议，包括客户端和服务器
** 实现集群功能，master-slave架构或者dht
** 实现rdb或者aof功能（可选）
** 提供一个接口方法，可以故障恢复

* 一致性
lamport算法确保一致性
但是不保证可用性
** 出现n台机器故障时，能否保证一致性

* 可用性
** 停机时间的约束：发生故障时停机多久
** 响应时间的约束：无故障平均响应时间和故障时平均响应时间，响应时间方差
** 从用户的角度看可用性，某个节点挂了后，必然会停机一段时间，直到找到另一个节点。

* 容错性
** 出现n台机器故障时，依然可用，且数据保持一致

* CAP问题的本质
** 容错保障可用性：
n个机器的集群中，发生k个故障时，是否能保证集群不停机，或者在短暂停机后继续可用。是否能保证数据依然是一致的。
** 容错保障一致性：
数据一致性的定义，如果告诉客户某个操作成功，那么最终使该操作在整个集群中成功。

* CAP问题困难的原因：
缺少网络模型和故障模型，使得无法量化可用性和容错性

* CAP是否真的是一个定理：
** 不停机和正常情况最优的可用性和实时一致性是不兼容的
** 不停机和正常情况最优的可用性和最终一致性是兼容的
** 暂停容忍和正常最优可用性和实时一致性是兼容的
** 暂停容忍和正常最优可用性和实时一致性是兼容的

* 网络故障模型？
既要考虑延迟，又要考虑故障导致分区，但没有数学模型；

* 分析：
所有机器都作为proposer和leaner，容错性和一致性很好，但是延迟高。

simple-paxos 正常工作时，延迟是最低的；但存在单点故障；单点故障时重选master；
为了解决单点故障，增加proposer，正常工作时不是最优的；

多个distinguished proposer和distinguished learner的情况下，极大的增加了达成一致需要的时间；增加了正常工作时的延迟；
多个distinguished proposer和distinguished learner的情况下，如果降低至最终一致性，正常情况下的延迟是最优的，而且不存在单点故障。

如何提供一个框架，使得分布式系统开发者可以直接选择自己的CAP策略，是非常有价值的。

* 最佳策略：
** 实现方式
正常工作时使用单master；master故障时，进入全proposer阶段，同时进行重选master；保持了一致性，正常工作时最优，故障时不停机；
故障时，进入全proposer，全learner模式，非常慢；
** 缺点：
master的压力大；每一个读写请求都要与master至少通信一次；
** 优化：
one distinguished proposer, multiple distinguished learner等价于把请求都路由给master

* 框架：
raft算法：
选举算法
master故障时重选master，同时退化到paxos算法；无master的paxos算法是有可能死锁的。
增加或者删除节点时，确保一致性；

现实中的分布式系统不仅仅是一个分布式状态机，而是状态机+计算

* 遗留问题
** 负载均衡与容错？
某一个节点故障后，client如何联系其他节点
mysql数据库的主从复制
mysql数据库的故障恢复
mysql数据库的单点故障
** 永远不停机的情况不存在
因为与client交互的是某一太机器，这台机器故障后，client必须能找到另一台机器来交互。

* 总结
CAP没有意义
设计一个分布式系统，应当先有一个应用或者目标，然后寻找解决方法。
* 继续折腾emacs
** speedbar
** ido
** frames
** smex
** percol
* 终于弄明白怎么杀掉某个进程了
ps aux | percol | awk '{ print $2}' | xargs kill
* 未来工作
** desktop
** theme
* c太复杂，这一次作业先使用go语言
* 学习使用c是一个长期的过程，这一次作业先使用go语言
* 分布式系统的驱动力
** 新的应用，deep learning
** 数据集增大
** 新的硬件
* 分布式系统industry problem
  1T data , 100bilian example 10 billian feature
* 目标
** effecient
** flexible concu model
** scala
** fault tolerence
** easy
* parameter server
** p2p / server 两种方式
** server 拆分为 server group

* RDMA
** CPU 50% 网络传输时
** InfiniBand + RDMA ： 共享内存模型
** 延迟非常低，带宽非常高
** 未来会成为网络主流标准。网速大于内存。
** 分布式变得非常简单
** raid buffer, 监控内存是否被别的机器写
** 适用于RDMA架构的模型：
Symmetic Model : pregel ,para server, hadoop 都是
** shared memory api
** locality awareness 利用本地性
** 分布式内存管理：
DHT 每台机器上的内存重新编址
** 内存一致性模型
分布式事务
乐观锁
** FaRM lock-free read

* TAO
** 10倍带宽，50倍延迟

* 互联网体系结构
** 定义
互联网是一门偏重实践性的工程技术学科，业界目前对其仍然没有明确，完整，统一的定义。Tanenbaum等奖互联网体系结构定义为分层和协议的集合，Peterson等将互联网体系结构定义为指导互联网设计与实现的通用蓝图。
更实际的观点则把互联网的体系结构看成互联网的模块化设计，有时也成为顶层设计。
** 主要问题
一般认为，互联网体系结构主要解决两个重要的问题，一是如何进行分层设计，即如何将互联网的功能分成不同的层次进行实现；二是边缘论，即在哪里实现这些功能。
** 分层是必然的吗？
from protocol stack to protocol heap-role-based architecture

* 未来网络
** IPV6
*** 地址资源问题
*** 增强安全功能
*** 保证服务质量
*** 协议CIDR，NAT缓解了该问题
何时能够取代IPV4并没有时间表
** QoS是目前热点
*** 本质上是研究网络资源的管理和控制。
*** 由于Internet的复杂性和基于分组交换的特点，使Internet本身缺乏完善的理论模型和分析。
*** DiffServ协议和RSVP协议
** 边缘论
*** Internet最重要的设计原则是“端到端的原则”，又称边缘论，其含义是能够在端系统实现的功能就不要在网络中实现。
*** 具体来说，就是Internet的网络层只提供不可靠的分组传输服务，而可靠性保证和安全性保证等应用需要的功能由端系统自己实现。
*** IPSEC和NAT功能的增加一定程度上破坏了Internet的端到端原则
<<<<<<< HEAD
* General Purpose Big Data Processing Framework
** 从数据角度分为两类：无共享数据和有共享数据
*** RDD
*** ParameterServer
** 共性问题：
*** 减少数据传输，数据本地性
*** 弹性调度，充分利用资源
*** 容错性
*** 灵活的一致性模型
** 可以改进的细节：
*** 运行时重新切分数据，弹性和数据本地性
*** 通信框架的改进，进一步减少数据传输
*** 粗粒度和细粒度的容错
*** 任务调度的灵活性：paraServer和spark是不同的
*** 不同算法要求的一致性是不同的，ml能更好的免疫扰动
** tradeoff：
*** 高效（不比任何专用框架差）
*** 通用（任何算法都能支持）
*** 简单（可能比专用的框架代码量略大）
* 未来工作计划
** 继续读Para和Piccolo，了解如何实现
** 做好大作业，找老师讨论
** 按照GPBDPF的思路做计划
** 做好我自己模块的工作计划安排
** 一个月做好资源调度模块
** 一个月做好任务调度模块
** 研究大数据应用和算法，分类
** unknown
* 如何做好docklet设计
** 原则：我不会接受别人替我做决策
** 原则：我不接受不符合逻辑的意见
** 原则：对于我不了解的部分，我不会指手画脚
** 画出设计图（2h)
** 写出readme，写出几个模块的设计文档框架(8h)
** 写出我自己模块的工作计划（2h）
* 无压工作的艺术
** goal：mind like water
** 行动来源于思想
** 原则：有效的处理内心的承诺，经测试非常有效
** 为什么有些事情总是念念不忘？
*** 你还没有确定它们的预期结果是什么
*** 你还没有决定你下一步的具体行动到底是什么
*** 你还没有把后果和即将采取行动的提示信息存入你所依赖的体系中
*** 大脑明察秋毫，你不可能糊弄自己的大脑。直到你澄清了所有的问题，作出一切必要的决定，并且把结果存储到系统中去，同时心里十分清楚，需要时你能够随时调用查询这个系统，你的大脑才能放松下来。
** 材料的转化
*** 材料：任何进入你的精神或现实世界但尚未找到归属的事情，所有你尚未推出理想的解决方案和下一步具体行动的事情。
*** 我们需要把所有我们尽力管理的材料转化为可以付诸行动的实情
** 管理行动
*** 事情极少因为缺乏时间而阻塞。他们陷入困境往往是由于未能判定行动而造成的。
*** 主要的变化：把一切赶出你的大脑：使用orgs
*** 同一个在你的大脑中没哟岗哨的敌人作战，是十分艰巨的任务
** 横向管理行动
*** 成功收集材料
**** 必备条件一：每一个悬而未决的问题都在你的收集系统中，而不是在你的大脑中
**** 必备条件二：尽可能地控制收集工具的数量，够用即可
**** 必备条件三：定期清空收集设备
*** 把一切赶出你的大脑
**** 收集工具应该成为你的生活方式的一部分。可以随心所欲地抓住任何一个极具潜力和使用价值的好主意、妙点子，把它们视为你生活中不可缺少的一部分。
*** 最大限度的减少收集设备的数量
**** 一些品德高尚的人天才人物在处理最少的问题时，却最为积极主动。by 达芬奇
*** 定期清空收集工具
**** 行动！行动！行动！
**** 堆积如山的to-do list让人士气大减
* Parameter Server研究工作
** 先完成go语言下的所有功能
** 读懂它的c/c++源码
** 思考可以改进的地方（从系统的角度）
** 学习机器学习和深度学习算法
** 从算法角度思考需要做出哪些优化
* goredis 0.2
** 改变存储方式，kv_cache
** 改变接口:主要是set和update
** 改变网络传输，使用non-blocking
** golang的同步原语，CAS？设置同步barriar
** 改变传输协议，不必兼容redis，使用google protocol
** 聚合优化：缓冲区，发送缓冲区，接收缓冲区，先聚合再发送
** 最重要的是：聚合优化，改变协议，改变存储，上述都做。
*** 1. 改为protobuf，测试解析是否成功
*** 2. 改变server的解析方式和实现方式。改为两个线程，收线程，kv操作线程,一个发送线程
*** 3. 修改client, loadGraph: 写操作聚合，一个线程
*** 4. 线程的问题可以最后再管
*** loadGraph：
1. loadgraph
写入 1.nodes: 2,3,4
1.count:3
*** pagerank:
第一步：初始值 1.rank= 1/total
写入
迭代：a.rank= 0.15*a.rank+0.85(sum(a.incr_rank))
      换成远程写的话：
      set( b.incr_rank, a.rank/a.count)
缺陷1：无法穿入远程聚合方法
缺陷2：没有聚合多个不同的key value
缺陷3：a.nodes 使用string保存？
* goredis readme
** 使用方式
*** 1.启动parameter server 1
parameterserver --ip 7.7.7.1 --port 7777 start server
*** 2.启动para server 2
parameterserver --ip 7.7.7.7 --port 7777 start server
*** 3.加载图数据
parameterserver start loadGraph
*** 4.启动pagerank的jobmaster
pagerank start master
*** 5.启动pagerank的worker
pagerank start worker
* git
** 查看remote origin
git remote show origin
* docklet readme
** why
** what
** how
** Architecture
** RoadMap
* Mellanox Store: Infiniband and Ethernet networking technologies
Mellanox Technologies is a leading supplier of end-to-end InfiniBand and Ethernet interconnect solutions and services for servers and storage. Mellanox interconnect solutions increase data center efficiency by providing the highest throughput and lowest latency, delivering data faster to applications and unlocking system performance capability. Mellanox offers a choice of fast interconnect products: adapters, switches, software, cables and silicon that accelerate application runtime and maximize business results for a wide range of markets including high-performance computing, enterprise data centers, Web 2.0, cloud, storage and financial services.
* how to manage a linux cluster
** pssh mussh
** IPMI
硬件厂商非常重视客户对远程管理系统标准的需求。当前，IPMI 2.0 已经成为大多数 Linux 集群的标准。IPMI 提供了远程控制机器电源的方法，还提供远程控制台，可以观察计算机的 BIOS 引导过程。在我们的一位客户的站点上，我们能够坐在客户的办公室中，舒舒服服地对 60 英里外的计算机进行调试。（这位客户的 Linux 管理员真的很懒惰，他的办公室只用墙上昏暗的霓虹灯来照明。这间办公室简直成了单身汉的公寓，这里有两个冰箱，装满了饮料和甜食。不用说，我们不愿意离开那里）。

IPMI 是强大的 —— 我们可以修改 BIOS 设置，重新启动节点，观察它们的引导过程，查看屏幕转储，而根本不需要看到物理机器 —— 它应该安装在所有集群中。您至少需要以下功能：
●远程控制机器的电源
●远程控制台或观察机器引导过程的更好方法，从而应付可能发生的引导问题

有了 IPMI，Linux 集群中就不太需要其他软件了，那些软件只提供运行 IPMI 的豪华界面，而不是管理节点。实际上，我们建议使用开放源码工具，比如大多数 Linux 发行版已经附带的 ipmitool。我们发现最懒惰的 Linux 集群管理员依赖于命令行。

对于 IPMI 远程控制台的可靠性还有争议。我们意识到，有时候真正的带外终端服务器是很有价值的。Cyclades ACS48 等终端服务器是合理的投资，它们提供带外访问和 IPMI 不具备的可靠性。

另外，IPMI 1.5 不是最可靠的 IOHO（这是一个全行业范围的问题）。IPMI 2.0 在这方面好多了，而且许多厂商围绕它添加了新颖的网页，使它看起来更容易使用。是包含终端服务器，还是只在机器上直接使用 IPMI，对于这个问题还有争议。我们的大多数客户的想法是这样的：每个懒惰的 Linux 管理员都知道，需要花费大量时间排除 5% 的节点的故障，而 95% 的节点都是正常的。在这种情况下，更好的办法是多购买 5% 的节点（而不是基础设施）当作备份。这意味着花费在计算能力上的预算比花费在基础设施上的预算多一些。

** 使用出色的集群管理软件 —— 工欲善其事，必先利其器

自从 1999 年 Linux 集群首次出现以来，集群工具已经有了长足的进步。在当时，可用的集群管理工具并不多，因此大多数管理员用自己开发的工具集来部署、监视和管理他们的集群。

最懒惰的管理员已经接受了开放源码工具，或者把他们在 1999 年开发的工具贡献给了社区。很少有开放源码工具无法应付的极其独特的集群环境。在大多数情况下，坚持使用自己的工具的管理员都很孤独，当他们离开组织时，他们的工具也就随其消失了。但是，我们发现在许多站点上仍然在使用定制的工具。

如果您对自制的工具不满意，正在寻找更好的工具，那么可以考虑几个开放源码工具。最受欢迎的集群管理工具包括 OSCAR (System Imager)、ROCKS、Perceus 和我们喜爱的 xCAT 2。它们都是开放源码的。
** 批量部署ssh私钥认证

** clustershell
* cfengine vs puppet vs chef
1. Cfengine vs Puppet vs Chef Ron Toland SCALE 2013
2. Background
3. Scenario
4. Common Features ● Flexible ● Configuration as Code ● Declarative DSL* * well, ok, not chef. but let's pretend.
5. Evaluation Criteria ● Footprint ● Scalability ● Documentation ● Learning Curve
6. Cfengine Footprint: Low
7. Cfengine Scalability: High
8. Cfengine Documentation: Terrible
9. Cfengine Learning Curve: Painful
10. Puppet Footprint: Ruby
11. Puppet Scalability: Tricky
12. Puppet Documentation: Excellent
13. Puppet Learning Curve: Gentle
14. Chef Footprint: Ruby + Friends
15. Chef Scalability: YES
16. Chef Documentation: Ok
17. Chef Learning Curve: Moderate
18. Recommendations
19. Small to Mid Scale: Puppet
20. Mid to Large Scale: Chef
21. Job Security: Cfengine
22. Further Reading ● Cfengine: http://cfengine.com/ ● Puppet: https://puppetlabs.com/ ● Pro Puppet, Turnbull & McCune ● Chef: http://www.opscode.com/chef/

* configuration tools
** why we use configuration tools
If you’re responsible for the care and feeding of multiple servers, and you haven’t heard about configuration management yet, you have not been paying attention.

* why CM is important
** from QA QC's perspect
• Control of test hardware and software used to define software component and product quality.
• Effective management of valuable test assets.
• Impact assessment for configuration and environment changes, including replacement and upgrade.
• Enable configuration progression and reversion.
• Single, centralised source of accurate and up to date configuration management information.
** For Develpers:
Many developers have experienced the frustration of unmanaged environments, where people overwrite each other’s changes or are unable to track revisions. Managing a large number of files or multiple developers is a challenge in any environment; as a result, large development projects rely upon configuration management tools to satisfy the following goals:

Provide access to a centralized repository of code
Manage and track multiple versions of the same applications
Manage multiple developers
Identify when changes are made and their impact
Detect and resolve conflicting changes
Distribute and deploy the latest versions of code
Back up and preserve access to older versions of code
Manage and distribute reuse libraries
** For Project Manager:
blab
* Trade off programming efforts with performance
** programming efforts
   MPI:                 e = mc^2
   parameter server:    e = mc
   Actor/MapReduce/RDD: e = m
   e: programming efforts
   c: data conflict between threads/processes/nodes
** infrastructure cost / performace is a constant in Cloud Computing
** suppose human cost / deduced programming efforts is a constant
** total benefit = base infrastructue cost/ base human cost /performance increase * deduced programming efforts
** suppose one program spend $100000 per year  on EC2, and need only 1 person*month development, cost $10000.
* iMatix is a Great Story teller
** No matter how large the problem, we break it down into clean layers that can be solved independently, and at each layer we define a minimal plausible internal architecture. This gives a clean minimal end-to-end skeleton.
** Our process goes way beyond Agile. We let developers self-organize around discrete problems supplied by expert users. This reduces the need for meetings, for evaluations, and prioritization.
** The saying goes, you don't want ninjas, you want ants. Ninjas are never there. Ants carry a hundred times their own weight and are great at working in teams. We're experts in helping the ants be happy and productive.
* Broker VS Switch
* LDAP协议
* RAMS
* 几个deep learning platform
** SINGA
** the executive vice president of Baidu Institue of Deep Learning Kai Yu announced PADDLE,
** their GPU counterpart to Google's DistBelief
** Adam Coates, Brody Huval, Tao Wang, David J. Wu, Andrew Y. Ng and Bryan Catanzaro. Deep Learning with COTS HPC. In ICML 2013.
** Large-scale Deep Learning at Baidu
** decaf
** Neon
* emacs org-mode export to markdown
M-x org-md-export-as-markdown
