<div id="table-of-contents">
<h2>Table of Contents</h2>
<div id="text-table-of-contents">
<ul>
<li><a href="#sec-1">1. Architecture overview</a>
<ul>
<li><a href="#sec-1-1">1.1. runs on IaaS provider or bare metal</a></li>
<li><a href="#sec-1-2">1.2. engineering challenges</a>
<ul>
<li><a href="#sec-1-2-1">1.2.1. 镜像快速搭建</a></li>
<li><a href="#sec-1-2-2">1.2.2. 垃圾回收</a></li>
<li><a href="#sec-1-2-3">1.2.3. 日志记录</a></li>
<li><a href="#sec-1-2-4">1.2.4. 密钥</a></li>
<li><a href="#sec-1-2-5">1.2.5. 文件系统</a></li>
<li><a href="#sec-1-2-6">1.2.6. 安全</a></li>
<li><a href="#sec-1-2-7">1.2.7. 镜像层和传输</a></li>
</ul>
</li>
<li><a href="#sec-1-3">1.3. its novelty of Docklet lies in the synergy achieved by picking the right systems technologie.</a></li>
<li><a href="#sec-1-4">1.4. core concepts</a></li>
<li><a href="#sec-1-5">1.5. architecture</a>
<ul>
<li><a href="#sec-1-5-1">1.5.1. 配置管理工具将被淘汰？</a></li>
<li><a href="#sec-1-5-2">1.5.2. kubernetes的资源调度几乎与mesos等价，是否还要把kubernetes运行在mesos上？</a></li>
<li><a href="#sec-1-5-3">1.5.3. 初步设想：</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
</div>

# Architecture overview<a id="sec-1" name="sec-1"></a>

## runs on IaaS provider or bare metal<a id="sec-1-1" name="sec-1-1"></a>

## engineering challenges<a id="sec-1-2" name="sec-1-2"></a>

### 镜像快速搭建<a id="sec-1-2-1" name="sec-1-2-1"></a>

为大型应用搭建容器镜像依旧是一项挑战。如果我们依靠容器镜像来进行测试、CI和应急部署，那么我们便须在1分钟内准备好这个镜像。Dockerfile的存在使其这对于大型应用而言基本是不可能的完成的事。纵使它易于使用，但是它的抽象层次太高，以至于不能应对复杂的用例：
为重量级的面向应用的依赖提供带外（out-of-band）缓存
在构建期间的访问密钥，避免提交到镜像
对于最终镜像层级的完全控制
层级构建的并行化

### 垃圾回收<a id="sec-1-2-2" name="sec-1-2-2"></a>

每个Docker的主要部署人员最终都会写一个垃圾回收器（以下简称GC），来移除主机中的旧镜像。这用到了各种方法，例如移除x天之前的镜像，并确保至多只有y个镜像存在主机中。Spotify最近也将它们开源了。很早之前，我们也一样实现了我们自己的GC。我能够理解为GC实现一个可预见的UI有多难，但这确实是最需要的东西。大多数人发现他们只是在其产品容器的空间不足时，才偶尔需要GC。最后，你也将会遇到这个问题：传到Docker Registry的相同镜像溢出为大镜像[译者：复数]，好在，这个问题已经在分布式规划中提出。

### 日志记录<a id="sec-1-2-3" name="sec-1-2-3"></a>

日志是本可以早点改进而获利的领域之一。它很难成为一个有吸引力的问题，但是它绝对是一个普遍性的问题。当前并没有优秀且通用的解决方案。这里充斥着各种方案：tail日志文件，记录到容器内，记录到挂载的主机，记录到主机的syslog，通过某些东西暴露日志(如fluentd)，通过应用记录到网络，或者是记录到一个文件并由另一个进程将日志发送到Kafka。Docker1.6支持合并到内核中的日志驱动；然而，驱动被内核采纳是很不容易的。1.7版本中，进程外插件被实验性支持，但是，令人失望的是，它并未附带日志驱动。我认为这将是1.8版本的计划，但并未找到任何官方记录。就这点来看，供应商未来将能够编写它们自己的日志驱动。或许，社区内分享将会变得微不足道，而且大型应用将不再需要定制解决方案。

### 密钥<a id="sec-1-2-4" name="sec-1-2-4"></a>

在“频繁而遍存”这一类目中，我们同样找到了密钥。大多数人在迁移容器时，依赖配置管理来安全地提供机器上的密钥；然而，因为密钥而一直采用同样的在配置管理路径并不太理想。一个可选方案是通过镜像来散布它们，但这具有安全隐患，并且会使得在开发、持续集成以及生产之间循环镜像变得困难。最纯粹的方案是通过网络获取密钥，保持镜像的文件系统无状态。直到最近，这个领域还不存在什么面向容器的解决方案，但是即将有2款引人注目的密钥代理开源，分别是Vault和Keywhiz。在Shopify，我们于一年半前开发了ejson来解决这个问题，它被用来管理JSON格式的非对称加密密钥文件；然而，它会对其运行环境做一定的假设，因此和密钥代理相比，显得不是那么通用(如果你感兴趣，可以阅读这篇文章)。

### 文件系统<a id="sec-1-2-5" name="sec-1-2-5"></a>

Docker依赖于文件系统的写时复制CoW（LWN上关于联合文件系统Union FS的系列文章，它们使CoW成为可能）。这项特性确保当你拥有100个容器时，不需要对应的100倍磁盘空间。每个容器都只是在镜像的顶部创建CoW层，它们只在改变原始镜像的文件时才使用必要的磁盘空间。好的容器使用者会尽可能避免对容器内部的文件系统产生影响，因为这意味着使容器保持某种状态，是为大忌。这种状态应该被存储在映射到主机的卷或者网络上。此外，层级存储能够在部署时节省空间，因为镜像通常是相似的，它们拥有一些共同的层。在Linux上支持CoW的问题在于它们太“新”了。在Shopify有几百台主机在重负荷下运行，这里有一些经验：
AUFS 曾发现在需要重新挂载时，整个分区被锁住的情况。迟钝且占用大量内存。代码基巨大，难以阅读，似乎这正是它不被上游接受的原因，因此需要一个定制的内核。
BTRFS 因为du和ls不能工作，新的工具集有一定的学习曲线。和AUFS一样，我们同样发现了分区冻结和内核锁死，不管我们如何更新内核版本。当接近磁盘空间上限时，BTRFS的行为变得不可预测，并且当我们拥有1000份CoW层(BTRFS中的子卷)时，BTRFS同样会占用大量内存。
OverlayFS 这在Linux3.18内核中并入，对于我们而言，它现在已经相当稳定和快速了。由于采用在inode间共享页缓存，它占用的内存少了很多。不幸的是，它需要你运行最新的内核，而这些内核往往未被大多数发行版采用，因此通常需要我们自己来编译一个。

所幸的是，对于Docker而言，Overlay很快就会普及了，而默认的AUFS对于产品而言依旧不太安全，根据我们的经验，这种情况在运行大量节点时尤甚。很难说这里需要做些什么，因为大多数发行版并未配备兼容Overlay的内核（Overlay被提议为默认FS，但是由于这里的原因最终被拒了）。虽然Overlay正是此领域的发展方向，不过我们还需等一阵子。

### 安全<a id="sec-1-2-6" name="sec-1-2-6"></a>

对于容器而言，运行时的安全在某种情况下依旧是一个问题，并且要让其对于产品足够“坚固”是一个经典“鸡与蛋”的安全问题。在我们的例子中，我们并不依靠容器提供任何额外的安全保证。不过，有些用例却这么做了。出于这个原因，大多数供应商依旧在虚拟机上运行容器，这种安全是经过考验过的。我希望在未来10年内看到虚拟机绝迹，因为操作系统虚拟化赢得了这场“战争”，正如某人曾经在Linux邮件列表中所说：“我曾听到过一种言论:管理程序的存在是操作系统无能的证据”。容器提供了介于虚拟机（硬件级虚拟化）和PaaS（应用层次）之间的完美的中庸之道。我知道更多对于运行时的改进已经完成，比如系统调用黑名单。围绕镜像的安全也已经引起关注，但是Docker正在通过libtrust和notary改进这个问题，后者是新的分布层的一部分。

### 镜像层和传输<a id="sec-1-2-7" name="sec-1-2-7"></a>

在Docker的第一次迭代中，它对于镜像构建、传输和运行时就走了一条捷径。它并不是针对每个问题选取正确的工具，而是选择了一个能够解决所有情况的工具：文件系统层。这种抽象一直暴露到在产品中运行容器。[译者：This abstraction leaks all the way down to running the container in production。大家自己理解下吧。。。]这是一种完全可以接受的最小成本的产品使用主义，但是其中的每个问题本都可以被更加有效地解决：
镜像创建 这项工作可以用有向图表示。它允许识别出可以缓存和并行化的部分，以完成快速的可预测的构建。
镜像传输 它完全可以使用二进制diff，而不是使用镜像层。这是一个已经研究了几十年的课题。分布层和运行时层变得越来越分离，开放了这方面的优化空间。
运行时 应该只是做一个单独的CoW层，而不是再次使用任意的镜像层抽象。如果你正在使用一个联合文件系统，比如AUFS，在第一次读取时，你需要便利一个文件链表来组装成最终的文件，缓慢且完全不必要的。

这个层次模型对于传输而言是一个问题（正如之前所述，对构建也一样）。这意味着，您需要格外关心镜像中的每一层有些什么东西，否则你可能轻易地需要为一个巨大的应用传输100多兆数据。如果在你的数据中心中有大量链接，这并不是什么大问题，但是我如果你希望使用诸如Docker Hub之类的注册服务，这可是在开放网络上传输的。镜像分布在继续工作着。这里有很多理由促使Docker公司让其变得坚固、安全和迅速。正如构建一样，我希望它能够对插件开放，以形成一个好的解决方案。与构建器相反，如果有诸如bittorrent分布的特殊机制，人们应该能够普遍认可。

## its novelty of Docklet lies in the synergy achieved by picking the right systems technologie.<a id="sec-1-3" name="sec-1-3"></a>

## core concepts<a id="sec-1-4" name="sec-1-4"></a>

## architecture<a id="sec-1-5" name="sec-1-5"></a>

### 配置管理工具将被淘汰？<a id="sec-1-5-1" name="sec-1-5-1"></a>

### kubernetes的资源调度几乎与mesos等价，是否还要把kubernetes运行在mesos上？<a id="sec-1-5-2" name="sec-1-5-2"></a>

### 初步设想：<a id="sec-1-5-3" name="sec-1-5-3"></a>

mesosphere用的组件也都是开源的，从github应该能找到大部分的。
dcos-cli是命令行
kubernetes-mesos把kubernetes运行在mesos上。
hdfs是HA HDFS on mesos
dcos-spark 是spark运行在mesos上
